{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd161af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('C:\\\\spark')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a61e52e2",
   "metadata": {},
   "source": [
    "## insanlar.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27d930b8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+----+--------+----+\n",
      "|     _corrupt_record|cinsiyet|  id|    isim| yas|\n",
      "+--------------------+--------+----+--------+----+\n",
      "|[{\"id\":1,\"isim\":\"...|    null|null|    null|null|\n",
      "|                null|  Female|   2|  Nadean|  29|\n",
      "|                null|    Male|   3| Edgardo|  67|\n",
      "|                null|  Female|   4|   Vonny|  59|\n",
      "|                null|    Male|   5|Hercules|  62|\n",
      "|                null|    Male|   6|   Lanny|  65|\n",
      "|                null|    Male|   7|  Norris|  19|\n",
      "|                null|  Female|   8|   Karia|  51|\n",
      "|                null|  Female|   9|  Korrie|  37|\n",
      "|                null|  Female|  10|  Hallie|  54|\n",
      "|                null|  Female|  11|   Aidan|  31|\n",
      "|                null|  Female|  12|   Lotte|  60|\n",
      "|                null|  Female|  13|    Zora|  28|\n",
      "|                null|  Female|  14|Odelinda|  46|\n",
      "|                null|    Male|  15|Basilius|  51|\n",
      "|                null|  Female|  16|   Irena|  52|\n",
      "|                null|    Male|  17|    Vite|  68|\n",
      "|                null|    Male|  18|     Ave|  47|\n",
      "|                null|    Male|  19| Vassili|  25|\n",
      "|                null|    Male|  20| Bastien|  62|\n",
      "|                null|  Female|  21|     Ola|  23|\n",
      "|                null|    Male|  22|   Meryl|  23|\n",
      "|                null|    Male|  23|   Nikki|  14|\n",
      "|                null|  Female|  24|     Joy|  59|\n",
      "|                null|    Male|  25|  Nikola|  38|\n",
      "|                null|    Male|  26|   Prent|  29|\n",
      "|                null|  Female|  27|   Amara|  38|\n",
      "|                null|  Female|  28|   Honor|  15|\n",
      "|                null|  Female|  29| Monique|  56|\n",
      "|                null|  Female|  30|     Fae|  61|\n",
      "|                null|  Female|  31|  Emilia|  69|\n",
      "|                null|  Female|  32|  Marley|  56|\n",
      "|                null|  Female|  33|  Bambie|  27|\n",
      "|                null|  Female|  34|   Dredi|  48|\n",
      "|                null|  Female|  35|   Mable|  29|\n",
      "|                null|  Female|  36| Dorelle|  43|\n",
      "|                null|  Female|  37|   Nonna|  54|\n",
      "|                null|    Male|  38|Algernon|  20|\n",
      "|                null|    Male|  39|  Antone|  19|\n",
      "|                null|    Male|  40|    Lyle|  27|\n",
      "|                null|  Female|  41|  Corina|  43|\n",
      "|                null|    Male|  42|   Homer|  24|\n",
      "|                null|    Male|  43| Sargent|  11|\n",
      "|                null|  Female|  44|   Marge|  67|\n",
      "|                null|    Male|  45|  Jessey|  33|\n",
      "|                null|  Female|  46|  Paloma|  52|\n",
      "|                null|    Male|  47|  Perice|  51|\n",
      "|                null|    Male|  48|     Joe|  59|\n",
      "|                null|  Female|  49|  Florri|  21|\n",
      "|                null|  Female|  50|    Dale|  18|\n",
      "+--------------------+--------+----+--------+----+\n",
      "only showing top 50 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"First_Example\").getOrCreate()\n",
    "df = spark.read.json(\".\\\\Pyspark_Humans_Data\\\\insanlar.json\")\n",
    "df.show(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0444d2e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "| yas|\n",
      "+----+\n",
      "|null|\n",
      "|  29|\n",
      "|  67|\n",
      "|  59|\n",
      "|  62|\n",
      "+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('yas').show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "61c2a8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|    isim|(yas + 10)|\n",
      "+--------+----------+\n",
      "|    null|      null|\n",
      "|  Nadean|        39|\n",
      "| Edgardo|        77|\n",
      "|   Vonny|        69|\n",
      "|Hercules|        72|\n",
      "+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(df['isim'],df['yas']+10).show(5)\n",
    "# df.select(df.isim, df.yas+10).show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43308f87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+--------+---+--------+---+\n",
      "|_corrupt_record|cinsiyet| id|    isim|yas|\n",
      "+---------------+--------+---+--------+---+\n",
      "|           null|  Female| 58|Tatiania| 21|\n",
      "|           null|  Female|413|   Dawna| 21|\n",
      "|           null|  Female| 83|  Marthe| 21|\n",
      "|           null|    Male|185|   Quint| 21|\n",
      "|           null|  Female| 49|  Florri| 21|\n",
      "|           null|  Female|312| Gunilla| 21|\n",
      "|           null|  Female|233|  Britte| 20|\n",
      "|           null|  Female|101| Bernita| 20|\n",
      "|           null|  Female|281|  Nancey| 20|\n",
      "|           null|    Male|340|   Micah| 20|\n",
      "+---------------+--------+---+--------+---+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.yas<22).orderBy('yas', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70d1fbbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-----+\n",
      "|yas|count|\n",
      "+---+-----+\n",
      "| 29|   15|\n",
      "| 45|   15|\n",
      "| 16|   13|\n",
      "| 43|   13|\n",
      "| 39|   13|\n",
      "| 51|   12|\n",
      "| 15|   12|\n",
      "| 50|   12|\n",
      "|  9|   12|\n",
      "| 41|   11|\n",
      "+---+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.groupBy('yas').count().orderBy('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cae918f",
   "metadata": {},
   "source": [
    "## ratings.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a17b61f1",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/zygmunt/goodbooks-10k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c4c47b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('C:\\\\spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eb3f8337",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import Row\n",
    "\n",
    "spark = SparkSession.builder.appName(\"SQL_BOOKS\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6a29a3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSV_ROW(row):\n",
    "    item = row.split(',')\n",
    "    return Row(book_id=int(item[0]), user_id=int(item[1]), rating=int(item[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "03451a29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'book_id,user_id,rating'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = spark.sparkContext.textFile(\".\\\\Pyspark_Books_Data\\\\ratings.csv\")\n",
    "header = rows.first()\n",
    "header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "46b03ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = rows.filter(lambda x: x!= header)\n",
    "books = rows.map(CSV_ROW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a161caa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|book_id|user_id|rating|\n",
      "+-------+-------+------+\n",
      "|      1|    314|     5|\n",
      "|      1|    439|     3|\n",
      "|      1|    588|     5|\n",
      "|      1|   1169|     4|\n",
      "|      1|   1185|     4|\n",
      "|      1|   2077|     4|\n",
      "|      1|   2487|     4|\n",
      "|      1|   2900|     5|\n",
      "|      1|   3662|     4|\n",
      "|      1|   3922|     5|\n",
      "+-------+-------+------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(books).cache()\n",
    "df.createOrReplaceTempView(\"books\")\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0503a1ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "981756"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datasette kac satir var?\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b4845186",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "980112"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datasette uniq kac satir var?\n",
    "df.distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "04635be1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Datasette uniq kac kitap var?\n",
    "df.groupBy('book_id').count().distinct().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1046de8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------------+\n",
      "|count(DISTINCT book_id)|\n",
      "+-----------------------+\n",
      "|                  10000|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative\n",
    "from pyspark.sql.functions import countDistinct\n",
    "df.select(countDistinct(\"book_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8e4f76ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|book_id|count|\n",
      "+-------+-----+\n",
      "|     65|  100|\n",
      "|    191|  100|\n",
      "|    418|  100|\n",
      "|    541|  100|\n",
      "|    558|  100|\n",
      "|   1010|  100|\n",
      "|   1224|  100|\n",
      "|   1258|  100|\n",
      "|   1277|  100|\n",
      "|   1360|  100|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Her kitabin kac defa oylandigini bulalim.\n",
    "df.groupBy('book_id').count().orderBy('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "19f5b94e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2544"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 100 den az veya fazla oylanmis olan kitap sayisi nedir?\n",
    "df2 = df.groupBy('book_id').count().orderBy('count', ascending=False)\n",
    "df2.filter(df2['count']!=100).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "32d3ed0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-----+\n",
      "|count|count|\n",
      "+-----+-----+\n",
      "|  100| 7456|\n",
      "|   99|  744|\n",
      "|   98|  329|\n",
      "|   97|  245|\n",
      "|   96|  159|\n",
      "|   95|  148|\n",
      "|   94|   93|\n",
      "|   93|   90|\n",
      "|   92|   74|\n",
      "|   91|   58|\n",
      "|   90|   55|\n",
      "|   89|   58|\n",
      "|   88|   39|\n",
      "|   87|   38|\n",
      "|   86|   37|\n",
      "|   85|   35|\n",
      "|   84|   31|\n",
      "|   83|   28|\n",
      "|   82|   17|\n",
      "|   81|   23|\n",
      "|   80|   12|\n",
      "|   79|   15|\n",
      "|   78|   19|\n",
      "|   77|   14|\n",
      "|   76|   21|\n",
      "|   75|   11|\n",
      "|   74|    8|\n",
      "|   73|   12|\n",
      "|   72|    7|\n",
      "|   71|    8|\n",
      "|   70|   13|\n",
      "|   69|   12|\n",
      "|   68|    4|\n",
      "|   67|   10|\n",
      "|   66|   11|\n",
      "|   65|   10|\n",
      "|   64|    4|\n",
      "|   63|    6|\n",
      "|   62|    3|\n",
      "|   61|    7|\n",
      "|   60|    5|\n",
      "|   59|    5|\n",
      "|   58|    1|\n",
      "|   57|    4|\n",
      "|   56|    1|\n",
      "|   55|    2|\n",
      "|   54|    3|\n",
      "|   53|    2|\n",
      "|   52|    3|\n",
      "|   48|    1|\n",
      "|   47|    1|\n",
      "|   46|    1|\n",
      "|   44|    1|\n",
      "|   41|    1|\n",
      "|   36|    1|\n",
      "|   34|    1|\n",
      "|   24|    1|\n",
      "|   11|    1|\n",
      "|    8|    1|\n",
      "+-----+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# uniq puanlama sayilarinin frekansa gore siralamasi\n",
    "df2.groupBy('count').count().orderBy('count', ascending=False).show(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15965806",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|book_id|count|\n",
      "+-------+-----+\n",
      "|   2244|   98|\n",
      "|   3628|   98|\n",
      "|   6642|   97|\n",
      "|   1308|   97|\n",
      "|   9566|   97|\n",
      "|   4483|   97|\n",
      "|   1904|   97|\n",
      "|   6920|   96|\n",
      "|   6527|   96|\n",
      "|   3275|   96|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rating i 4 ve uzeri kitaplari getir\n",
    "spark.sql(\"SELECT * FROM books WHERE rating>=4\").groupBy('book_id').count().orderBy('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5b653435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|book_id|count|\n",
      "+-------+-----+\n",
      "|   2244|   98|\n",
      "|   3628|   98|\n",
      "|   6642|   97|\n",
      "|   1904|   97|\n",
      "|   1308|   97|\n",
      "|   9566|   97|\n",
      "|   4483|   97|\n",
      "|   3275|   96|\n",
      "|   6920|   96|\n",
      "|   3660|   96|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative\n",
    "df.filter(df['rating']>=4).groupBy('book_id').count().orderBy('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b80f9497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|book_id|count|\n",
      "+-------+-----+\n",
      "|   1793|   39|\n",
      "|     34|   29|\n",
      "|   1409|   26|\n",
      "|      3|   23|\n",
      "|   4009|   23|\n",
      "|   1822|   22|\n",
      "|   3550|   22|\n",
      "|   1338|   22|\n",
      "|   8466|   21|\n",
      "|   4399|   21|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# rating i 2 nin alti kitaplari getir\n",
    "spark.sql(\"SELECT * FROM books WHERE rating < 2\").groupBy('book_id').count().orderBy('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5dae3f3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|book_id|count|\n",
      "+-------+-----+\n",
      "|   1793|   39|\n",
      "|     34|   29|\n",
      "|   1409|   26|\n",
      "|      3|   23|\n",
      "|   4009|   23|\n",
      "|   1822|   22|\n",
      "|   3550|   22|\n",
      "|   1338|   22|\n",
      "|   4399|   21|\n",
      "|   8466|   21|\n",
      "+-------+-----+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative\n",
    "df.filter(df['rating']<2).groupBy('book_id').count().orderBy('count', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "15f54c2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+\n",
      "|book_id|      avg(rating)|\n",
      "+-------+-----------------+\n",
      "|   7947|4.820224719101123|\n",
      "|   5207|             4.78|\n",
      "|   6920|             4.78|\n",
      "|   9566|4.777777777777778|\n",
      "|   8946|4.774193548387097|\n",
      "|   6361|             4.77|\n",
      "|   3275|             4.77|\n",
      "|   6590|             4.75|\n",
      "|   4483|             4.75|\n",
      "|   5580|             4.75|\n",
      "+-------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ortalama ratingi en yuksek 10 kitabi getir\n",
    "df.groupBy('book_id').mean('rating').orderBy('avg(rating)', ascending=False).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "39ee2ad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|book_id|       avg(rating)|\n",
      "+-------+------------------+\n",
      "|   1793|              1.96|\n",
      "|   4045| 2.235294117647059|\n",
      "|   7636|            2.3125|\n",
      "|   1822| 2.350515463917526|\n",
      "|   1409|              2.43|\n",
      "|   4399|2.4574468085106385|\n",
      "|   4991| 2.462686567164179|\n",
      "|   3550|              2.49|\n",
      "|   4009|              2.53|\n",
      "|   4283|              2.54|\n",
      "+-------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Ortalama ratingi en dusuk 10 kitabi getir\n",
    "df.groupBy('book_id').mean('rating').orderBy('avg(rating)', ascending=True).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c3c2aec4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|book_id|       avg(rating)|\n",
      "+-------+------------------+\n",
      "|   1793|              1.96|\n",
      "|   4045| 2.235294117647059|\n",
      "|   7636|            2.3125|\n",
      "|   1822| 2.350515463917526|\n",
      "|   1409|              2.43|\n",
      "|   4399|2.4574468085106385|\n",
      "|   4991| 2.462686567164179|\n",
      "|   3550|              2.49|\n",
      "|   4009|              2.53|\n",
      "|   4283|              2.54|\n",
      "+-------+------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Alternative\n",
    "spark.sql(\"SELECT * FROM books\").groupBy('book_id').mean('rating').orderBy('avg(rating)', ascending=True).show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "da03b628",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------+\n",
      "|book_id|user_id|rating|\n",
      "+-------+-------+------+\n",
      "|      1|    314|     5|\n",
      "|      1|    439|     3|\n",
      "|      1|    588|     5|\n",
      "|      1|   1169|     4|\n",
      "|      1|   1185|     4|\n",
      "|      1|   2077|     4|\n",
      "|      1|   2487|     4|\n",
      "|      1|   2900|     5|\n",
      "|      1|   3662|     4|\n",
      "|      1|   3922|     5|\n",
      "|      1|   5379|     5|\n",
      "|      1|   5461|     3|\n",
      "|      1|   5885|     5|\n",
      "|      1|   6630|     5|\n",
      "|      1|   7563|     3|\n",
      "|      1|   9246|     1|\n",
      "|      1|  10140|     4|\n",
      "|      1|  10146|     5|\n",
      "|      1|  10246|     4|\n",
      "|      1|  10335|     4|\n",
      "+-------+-------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc5382f",
   "metadata": {},
   "source": [
    "## Video_Games_Sales_as_at_22_Dec_2016.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1bd6040",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/datasets/rush4ratio/video-game-sales-with-ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a805a66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('C:\\\\spark')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8cc62dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2eef19e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Name: string, Platform: string, Year_of_Release: string, Genre: string, Publisher: string, NA_Sales: string, EU_Sales: string, JP_Sales: string, Other_Sales: string, Global_Sales: string, Critic_Score: string, Critic_Count: string, User_Score: string, User_Count: string, Developer: string, Rating: string]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = spark.read.format(\"csv\").option(\"header\", \"true\").load(\".\\\\Pyspark_Video_Games_Data\\\\Video_Games_Sales_as_at_22_Dec_2016.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4b34d799",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Platform='PS2', count=2161),\n",
       " Row(Platform='DS', count=2152),\n",
       " Row(Platform='PS3', count=1331),\n",
       " Row(Platform='Wii', count=1320),\n",
       " Row(Platform='X360', count=1262),\n",
       " Row(Platform='PSP', count=1209),\n",
       " Row(Platform='PS', count=1197),\n",
       " Row(Platform='PC', count=974),\n",
       " Row(Platform='XB', count=824),\n",
       " Row(Platform='GBA', count=822),\n",
       " Row(Platform='GC', count=556),\n",
       " Row(Platform='3DS', count=520),\n",
       " Row(Platform='PSV', count=432),\n",
       " Row(Platform='PS4', count=393),\n",
       " Row(Platform='N64', count=319),\n",
       " Row(Platform='XOne', count=247),\n",
       " Row(Platform='SNES', count=239),\n",
       " Row(Platform='SAT', count=173),\n",
       " Row(Platform='WiiU', count=147),\n",
       " Row(Platform='2600', count=133),\n",
       " Row(Platform='NES', count=98),\n",
       " Row(Platform='GB', count=98),\n",
       " Row(Platform='DC', count=52),\n",
       " Row(Platform='GEN', count=29),\n",
       " Row(Platform='NG', count=12),\n",
       " Row(Platform='SCD', count=6),\n",
       " Row(Platform='WS', count=6),\n",
       " Row(Platform='3DO', count=3),\n",
       " Row(Platform='TG16', count=2),\n",
       " Row(Platform='PCFX', count=1),\n",
       " Row(Platform='GG', count=1)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset.groupby(\"Platform\").count().orderBy(\"count\", ascending = False)\n",
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ec115ec0-5dce-49fb-8b7d-73c4bcf7eaea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(Genre='Action', count=3370),\n",
       " Row(Genre='Sports', count=2348),\n",
       " Row(Genre='Misc', count=1750),\n",
       " Row(Genre='Role-Playing', count=1500),\n",
       " Row(Genre='Shooter', count=1323),\n",
       " Row(Genre='Adventure', count=1303),\n",
       " Row(Genre='Racing', count=1249),\n",
       " Row(Genre='Platform', count=888),\n",
       " Row(Genre='Simulation', count=874),\n",
       " Row(Genre='Fighting', count=849),\n",
       " Row(Genre='Strategy', count=683),\n",
       " Row(Genre='Puzzle', count=580),\n",
       " Row(Genre=None, count=2)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = dataset.groupBy('Genre').count().orderBy('count',ascending=False)\n",
    "data.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "77c1f2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Name',\n",
       " 'Platform',\n",
       " 'Year_of_Release',\n",
       " 'Genre',\n",
       " 'Publisher',\n",
       " 'NA_Sales',\n",
       " 'EU_Sales',\n",
       " 'JP_Sales',\n",
       " 'Other_Sales',\n",
       " 'Global_Sales',\n",
       " 'Critic_Score',\n",
       " 'Critic_Count',\n",
       " 'User_Score',\n",
       " 'User_Count',\n",
       " 'Developer',\n",
       " 'Rating']"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rows = spark.sparkContext.textFile(\".\\\\Pyspark_Video_Games_Data\\\\Video_Games_Sales_as_at_22_Dec_2016.csv\")\n",
    "header = rows.first()\n",
    "header.split(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c22032b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def CSV_ROW(row):\n",
    "    global header\n",
    "    a=header.split(',')\n",
    "    item = row.split(',')\n",
    "    return Row(Name=item[0], Platform=item[1], Year_of_Release=item[2], Genre=item[3], \n",
    "               Publisher=item[4], EU_Sales=item[6], Developer=item[13], Rating=item[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "fd6064f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = rows.filter(lambda x: x!= header)\n",
    "books = rows.map(CSV_ROW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "635c60e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+---------------+------------+---------+--------+---------+--------+\n",
      "|                Name|Platform|Year_of_Release|       Genre|Publisher|EU_Sales|Developer|  Rating|\n",
      "+--------------------+--------+---------------+------------+---------+--------+---------+--------+\n",
      "|          Wii Sports|     Wii|           2006|      Sports| Nintendo|   28.96|      322|Nintendo|\n",
      "|   Super Mario Bros.|     NES|           1985|    Platform| Nintendo|    3.58|         |        |\n",
      "|      Mario Kart Wii|     Wii|           2008|      Racing| Nintendo|   12.76|      709|Nintendo|\n",
      "|   Wii Sports Resort|     Wii|           2009|      Sports| Nintendo|   10.93|      192|Nintendo|\n",
      "|Pokemon Red/Pokem...|      GB|           1996|Role-Playing| Nintendo|    8.89|         |        |\n",
      "|              Tetris|      GB|           1989|      Puzzle| Nintendo|    2.26|         |        |\n",
      "|New Super Mario B...|      DS|           2006|    Platform| Nintendo|    9.14|      431|Nintendo|\n",
      "|            Wii Play|     Wii|           2006|        Misc| Nintendo|    9.18|      129|Nintendo|\n",
      "|New Super Mario B...|     Wii|           2009|    Platform| Nintendo|    6.94|      594|Nintendo|\n",
      "|           Duck Hunt|     NES|           1984|     Shooter| Nintendo|    0.63|         |        |\n",
      "+--------------------+--------+---------------+------------+---------+--------+---------+--------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.createDataFrame(books).cache()\n",
    "df.createOrReplaceTempView('books')\n",
    "df.show(10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
